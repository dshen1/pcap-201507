---
title: "Dynamic reporting and visualization for data science"
author: "Kevin Kuo"
date: "July 25, 2015"
output:
  ioslides_presentation:
    smaller: true
---

```{R, include = FALSE}
library(magrittr)
```

## Data visualization - why it matters

- Quicker exploration of data
    + Charts and plots are often easier to digest than a bunch of numbers

> - Better exploration of data
    + Humans are not so good at detecting patterns from numbers
    
> - Powerful messaging
    + People trust you more if you have fancy graphics to point to

## Reproducibility - why it matters

- How did you get this number? It looks way off.
    + We `Ctrl-C` from this other workbook which had 20 linked formula dependencies then `Alt-E,S,V` here, but someone modified the source file so now we have no idea what's going on.

> - The client just gave us an updated dataset, we need to update the report for the meeting tomorrow.
    + Looks like we're not sleeping tonight, we gotta re-run the SAS scripts, copy the results into Excel, format, make some charts, then copy those into Word and PowerPoint for the presentation :(

## This talk

* All examples are done in R

* All code, including that to generate this deck, is available on [GitHub](https://github.com/kykuo/pcap-201507)

# Case Study 1: Tornado data exploration

## Tornado data exploration

- Storm events data (2010 ~ 2013) from NOAA (National Oceanic and Atmospheric Administration)

```{R}
list.files("download/")
```

## Tornado data exploration {.smaller}

```{R, message = FALSE, warning = FALSE}
library(readr)
library(magrittr)
"download/stormdata_2010.csv" %>%
  read_csv %>%
  names
```

## Tornado data exploration {.smaller}

```{R, message = FALSE, warning = FALSE}
source("R/tornado.R") # some data munging code
library(DT)
stormData %>%
  filter(type == "Tornado") %>%
  datatable(filter="top", rownames=FALSE, options=list(pageLength=5, dom='tp'))
```

## Tornado data exploration

- Here's a quick plot of daily tornado *counts*:

```{R, echo = FALSE}
dygraph(stormTS) %>%
  dyOptions(stackedGraph = TRUE) %>%
  dyRangeSelector()
```

## Tornado data exploration {.smaller}

* Let's focus on the outbreak period and look at stats by state:

```{R, message = FALSE, warning = FALSE}
stormData %>%
  filter(type == "Tornado",
         date >= ymd("2011-4-25"), date <= ymd("2011-4-28")) %>%
  group_by(state) %>%
  summarize(count = n(),
            deaths = sum(deaths)) %>%
  datatable(rownames = FALSE, options = list(pageLength=5, dom='tp'))
```

## Tornado data exploration

- Here is a map of the tornados during the four years:

```{R, echo = FALSE}
library(leaflet)
counties %>%
  leaflet() %>%
  addTiles() %>%
  addPolygons(stroke = FALSE, smoothFactor = 0.2, 
              fillOpacity = 0.8, fillColor = ~ pal(count),
              popup = countyPopup) %>%
  addCircleMarkers(data = outbreakOccurences, 
                   lng = ~ long, lat = ~ lat, 
                   radius = ~ sqrt(10*deaths),
                   fillOpacity = 0.2, color = "blue", 
                   stroke = FALSE, popup = deathPopup)
```

## Tornado data exploration

- Excerpt of the code for the map on the previous page:

```{R, eval = FALSE}
library(leaflet)
counties %>%
  leaflet() %>%
  addTiles() %>%
  addPolygons(stroke = FALSE, smoothFactor = 0.2, 
              fillOpacity = 0.8, fillColor = ~ pal(count),
              popup = countyPopup) %>%
  addCircleMarkers(data = outbreakOccurences, 
                   lng = ~ long, lat = ~ lat, 
                   radius = ~ sqrt(10*deaths),
                   fillOpacity = 0.2, color = "blue", 
                   stroke = FALSE, popup = deathPopup)
```

> - Since it's just text, put it under source control!

# Case study 2: Insurer-Reinsurer relationships

## Insurer-Reinsurer relationships {.smaller}

- Make up some (re)insurance companies and treaties:

```{R, message = FALSE, warning = FALSE}
source("R/network-graph.R")
sample_n(companies, 4)
sample_n(treaties, 4)
```

## Insurer-reinsurer relationships

```{R, results = "asis"}
forceNetwork(Links = treaties, Nodes = companies, 
             Source = "cedant", Target = "reinsurer",
             Value = "premiumCeded", NodeID = "company", Nodesize = "size",
             Group = "group", opacity = 0.8,
             colourScale = "d3.scale.category10()")
```

# Case study 3: Predictive modeling

## Predictive modeling

- For this case study, we'll use the `Insurance` dataset from the MASS package.

```{R, include = FALSE}
source("R/glm-example.R")
```

```{R, echo = FALSE}
head(Insurance2, 10)
```

- We'll fit poisson regression models to predict claim count and validate results graphically

## Predictive modeling {.smaller}

- Here's a 3-fold relativity table. If the model is *stable* we would expect the estimates to be similar across different samples.

```{R, message = FALSE, warning = FALSE, echo = FALSE}
library(DT)
relativities %>% 
datatable %>% 
formatRound(2:(nFolds + 1), digits = 2)
```

## Predictive modeling

- Here's an example where a picture more appropriate than numbers

```{R, echo = FALSE}
relativityPlots[[1]]
```

## Predictive modeling

- Here is an out-of-sample predicted vs. actual plot, which shows how the model performs in each quantile range of the predicted values:

```{R, echo = FALSE, message = FALSE}
library(rcdimple)
liftChartData %>%
dimple(x = c("bin", "variable"), y = "value", type = "bar", groups = "variable") %>%
xAxis(type = "addCategoryAxis", title = "Predicted quantile") %>%
yAxis(type = "addMeasureAxis", title = "Value") %>%
add_legend() %>%
add_title("Out of sample lift chart")
```

## Predictive modeling

BTW, in a real life *predictive modeling* exercise, consider

- having a hold-out validation set and looking at quantitative error metrics

- using other techniques in addition to or instead of GLMs, unless you're constrained by regulation

- *not* using stepwise regression and using regularization if you're stuck doing GLMs

- *not* looking at p-values and frequentist CIs


# That's it!
